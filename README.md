# ğŸ§  Cloven_Tectum Framework

> *â€œThe tectum in the human brain orients the body and eyes toward relevant stimuli.  
This framework applies the same principle: orient AI systems toward **meaningful signal**, shielding them from distortion and noise.â€*

---

## âš™ï¸ Build Info
- Version: 0.1.0
- Commit:  1a6b99a
- Date:    2025-09-28

---

## ğŸ“– Overview

The **Cloven_Tectum Framework (CTF)** is a **framework for resilient stacks of services** â€” repeatable, self-deploying, and adaptable.  
It combines a **robust backend** (PostgreSQL + FastAPI), **modern AI runtimes** (Ollama, Open WebUI), and **modular agents** (scrapers, inserters) to create a **fault-tolerant narrative system**.  

This project was built with a **DevOps-first mindset**:
- ğŸ› ï¸ **Self-deploying bootstrap script (`serversetup.sh`)**
- ğŸ³ **Dockerized services with Compose orchestration**
- ğŸ”„ **Iterative updates and auto-generated README metadata**
- ğŸ§© **Extensible design** for plugging in new AI models and agents

---

## ğŸ—‚ï¸ Project Structure


Cloven_Distro_TectumFW/
â”œâ”€ ABOUT.md                 # About page (image, version, commit info)
â”œâ”€ assets/                  # Static assets
â”œâ”€ .env / .env.example      # Environment configuration (DB, ports, etc.)
â”œâ”€ tectum_framework/        # Core framework
â”‚  â”œâ”€ api_server/           # FastAPI app (core API services)
â”‚  â”œâ”€ ollama/               # Ollama container for LLM serving
â”‚  â”œâ”€ agents/               # Modular agents
â”‚  â”‚  â”œâ”€ scraper/           # Scraping & ingestion logic
â”‚  â”‚  â””â”€ inserter/          # Inserts data into DB
â”œâ”€ docker-compose.yml       # Orchestrates all containers
â”œâ”€ serversetup.sh           # Bootstrapper (generates files, sets perms, launches stack)
â”œâ”€ update_readme.sh         # Auto-updates README from template + Git metadata
â””â”€ README.template.md       # Template used by update_readme.sh


---

## ğŸ—ï¸ Stack Architecture

```mermaid
flowchart TB
    subgraph U[User Layer]
        A[WebUI] -->|Requests| API
    end

    subgraph F[Framework Layer]
        API[FastAPI Server] -->|Inserts| DB[(PostgreSQL + pgvector)]
        API --> Ollama[Ollama Runtime]
        API --> Agents[Scraper + Inserter]
    end

    subgraph S[Storage & State]
        DB[(PostgreSQL DB)]
    end

    subgraph V[Visualization]
        A[WebUI] -->|Models & Results| Ollama
    end
âš¡ Parallel Task Execution (Multiple LLMs)
mermaid
Copy code
flowchart TB
    U[User / WebUI] -->|Task Request| G[Cloven_Tectum API]

    subgraph O[Ollama Runtime]
        L1[LLM Instance 1]
        L2[LLM Instance 2]
        L3[LLM Instance 3]
        L4[LLM Instance N]
    end

    G -->|Fan Out Tasks| L1
    G --> L2
    G --> L3
    G --> L4

    L1 -->|Partial Result| G
    L2 -->|Partial Result| G
    L3 -->|Partial Result| G
    L4 -->|Partial Result| G
    
    G -->|Aggregate & Respond| U
    end

Explanation
A single user request â†’ API fans out tasks to multiple Ollama-hosted models.
Each LLM runs in parallel, producing partial outputs.
Results are aggregated back at the API and returned as a unified response.
This pattern makes the system resilient, scalable, and fast.

ğŸš€ Quickstart
1. Clone the repo
bash
Copy code
git clone https://github.com/cycotek/Cloven_Distro_TectumFW.git
cd Cloven_Distro_TectumFW
2. Bootstrap the stack
bash
Copy code
./serversetup.sh
This will:

Create required directories

Generate .env (if missing)

Write Dockerfiles + docker-compose.yml

Launch all services (API, Ollama, DB, WebUI, agents)

3. Access services
API docs â†’ http://localhost:8000/docs

WebUI (OpenWebUI) â†’ http://localhost:8080

ğŸ”® Roadmap
âœ… Bootstrapper script (serversetup.sh)
âœ… Basic FastAPI + Ollama + WebUI stack
âœ… Agents for scraping/inserting

ğŸ”² Narrative drift detection (DB-backed replicas)
ğŸ”² Real-time metadata analysis (sentiment, credibility, demographics)
ğŸ”² Home Assistant integration
ğŸ”² GPU support variants (NVIDIA/AMD/CPU fallback)
ğŸ”² Voice packages for OpenWebUI

ğŸ§© Philosophy & Easter Eggs
â€œNo gods, no devils, only uptime.â€ â†’ Resilience as philosophy.

Narrative redundancy â†’ Multiple models defend against distortion.

Transparency â†’ Logs, metrics, and self-healing workflows.

Easter Eggs â†’ Source contains hidden lyrics & acknowledgements ğŸ˜‰.

ğŸ“ License
MIT License Â© 2025 Cycotek & Contributors
